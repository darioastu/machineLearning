{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepasoSemana6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpkLdLbz5zPcv9GInbKKeP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darioastu/machineLearning/blob/master/RepasoSemana6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIAiQRHIClh4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "from math import ceil,floor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWoqzR9PCuNt"
      },
      "source": [
        "class PongAgent:\n",
        "    \n",
        "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
        "\n",
        "        # Creamos la tabla de politicas\n",
        "        if policy is not None:\n",
        "            self._q_table = policy\n",
        "        else:\n",
        "            position = list(game.positions_space.shape)\n",
        "            position.append(len(game.action_space))\n",
        "            self._q_table = np.zeros(position)\n",
        "        \n",
        "        self.discount_factor = discount_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ratio_explotacion = ratio_explotacion\n",
        "\n",
        "    def get_next_step(self, state, game):\n",
        "        \n",
        "        # Damos un paso aleatorio...\n",
        "        next_step = np.random.choice(list(game.action_space))\n",
        "        \n",
        "        # o tomaremos el mejor paso...\n",
        "        if np.random.uniform() <= self.ratio_explotacion:\n",
        "            # tomar el maximo\n",
        "            idx_action = np.random.choice(np.flatnonzero(\n",
        "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
        "                ))\n",
        "            next_step = list(game.action_space)[idx_action]\n",
        "\n",
        "        return next_step\n",
        "\n",
        "    # actualizamos las politicas con las recompensas obtenidas\n",
        "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
        "        idx_action_taken =list(game.action_space).index(action_taken)\n",
        "\n",
        "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
        "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
        "\n",
        "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
        "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
        "        if reached_end:\n",
        "            future_max_q_value = reward_action_taken #maximum reward\n",
        "\n",
        "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
        "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
        "    \n",
        "    def print_policy(self):\n",
        "        for row in np.round(self._q_table,1):\n",
        "            for column in row:\n",
        "                print('[', end='')\n",
        "                for value in column:\n",
        "                    print(str(value).zfill(5), end=' ')\n",
        "                print('] ', end='')\n",
        "            print('')\n",
        "            \n",
        "    def get_policy(self):\n",
        "        return self._q_table"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGFb9b-NCyOn"
      },
      "source": [
        "class PongEnvironment:\n",
        "    \n",
        "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
        "        \n",
        "        self.action_space = ['Arriba','Abajo']\n",
        "        \n",
        "        self._step_penalization = 0\n",
        "        \n",
        "        self.state = [0,0,0]\n",
        "        \n",
        "        self.total_reward = 0\n",
        "        \n",
        "        self.dx = movimiento_px\n",
        "        self.dy = movimiento_px\n",
        "        \n",
        "        filas = ceil(height_px/movimiento_px)\n",
        "        columnas = ceil(width_px/movimiento_px)\n",
        "        \n",
        "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
        "                                                  for y in range(filas)] \n",
        "                                                     for x in range(filas)])\n",
        "\n",
        "        self.lives = max_life\n",
        "        self.max_life=max_life\n",
        "        \n",
        "        self.x = randint(int(width_px/2), width_px) \n",
        "        self.y = randint(0, height_px-10)\n",
        "        \n",
        "        self.player_alto = int(height_px/4)\n",
        "\n",
        "        self.player1 = self.player_alto  # posic. inicial del player\n",
        "        \n",
        "        self.score = 0\n",
        "        \n",
        "        self.width_px = width_px\n",
        "        self.height_px = height_px\n",
        "        self.radio = 2.5\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_reward = 0\n",
        "        self.state = [0,0,0]\n",
        "        self.lives = self.max_life\n",
        "        self.score = 0\n",
        "        self.x = randint(int(self.width_px/2), self.width_px) \n",
        "        self.y = randint(0, self.height_px-10)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, animate=False):\n",
        "        self._apply_action(action, animate)\n",
        "        done = self.lives <=0 # final\n",
        "        reward = self.score\n",
        "        reward += self._step_penalization\n",
        "        self.total_reward += reward\n",
        "        return self.state, reward , done\n",
        "\n",
        "    def _apply_action(self, action, animate=False):\n",
        "        \n",
        "        if action == \"Arriba\":\n",
        "            self.player1 += abs(self.dy)\n",
        "        elif action == \"Abajo\":\n",
        "            self.player1 -= abs(self.dy)\n",
        "            \n",
        "        self.avanza_player()\n",
        "\n",
        "        self.avanza_frame()\n",
        "\n",
        "        if animate:\n",
        "            clear_output(wait=True);\n",
        "            fig = self.dibujar_frame()\n",
        "            plt.show()\n",
        "\n",
        "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
        "    \n",
        "    def detectaColision(self, ball_y, player_y):\n",
        "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    \n",
        "    def avanza_player(self):\n",
        "        if self.player1 + self.player_alto >= self.height_px:\n",
        "            self.player1 = self.height_px - self.player_alto\n",
        "        elif self.player1 <= -abs(self.dy):\n",
        "            self.player1 = -abs(self.dy)\n",
        "\n",
        "    def avanza_frame(self):\n",
        "        self.x += self.dx\n",
        "        self.y += self.dy\n",
        "        if self.x <= 3 or self.x > self.width_px:\n",
        "            self.dx = -self.dx\n",
        "            if self.x <= 3:\n",
        "                ret = self.detectaColision(self.y, self.player1)\n",
        "\n",
        "                if ret:\n",
        "                    self.score = 10\n",
        "                else:\n",
        "                    self.score = -10\n",
        "                    self.lives -= 1\n",
        "                    if self.lives>0:\n",
        "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "                        self.y = randint(0, self.height_px-10)\n",
        "                        self.dx = abs(self.dx)\n",
        "                        self.dy = abs(self.dy)\n",
        "        else:\n",
        "            self.score = 0\n",
        "\n",
        "        if self.y < 0 or self.y > self.height_px:\n",
        "            self.dy = -self.dy\n",
        "\n",
        "    def dibujar_frame(self):\n",
        "        fig = plt.figure(figsize=(5, 4))\n",
        "        a1 = plt.gca()\n",
        "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
        "        a1.set_ylim(-5, self.height_px+5)\n",
        "        a1.set_xlim(-5, self.width_px+5)\n",
        "\n",
        "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
        "        a1.add_patch(circle);\n",
        "        a1.add_patch(rectangle)\n",
        "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
        "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
        "        if self.lives <=0:\n",
        "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
        "        elif self.total_reward >= 1000:\n",
        "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
        "        return fig"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFPcFNN4C1oY"
      },
      "source": [
        "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
        "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
        "\n",
        "    if game is None:\n",
        "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
        "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
        "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
        "        \n",
        "    if learner is None:\n",
        "        print(\"Begin new Train!\")\n",
        "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
        "\n",
        "    max_points= -9999\n",
        "    first_max_reached = 0\n",
        "    total_rw=0\n",
        "    steps=[]\n",
        "\n",
        "    for played_games in range(0, rounds):\n",
        "        state = game.reset()\n",
        "        reward, done = None, None\n",
        "        \n",
        "        itera=0\n",
        "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
        "            old_state = np.array(state)\n",
        "            next_action = learner.get_next_step(state, game)\n",
        "            state, reward, done = game.step(next_action, animate=animate)\n",
        "            if rounds > 1:\n",
        "                learner.update(game, old_state, next_action, reward, state, done)\n",
        "            itera+=1\n",
        "        \n",
        "        steps.append(itera)\n",
        "        \n",
        "        total_rw+=game.total_reward\n",
        "        if game.total_reward > max_points:\n",
        "            max_points=game.total_reward\n",
        "            first_max_reached = played_games\n",
        "        \n",
        "        if played_games %500==0 and played_games >1 and not animate:\n",
        "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
        "                \n",
        "    if played_games>1:\n",
        "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
        "        \n",
        "    #learner.print_policy()\n",
        "    \n",
        "    return learner, game"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_CYa0WsC8Tb",
        "outputId": "736a3463-ed0d-4978-e3fa-d2fc48aa9d1e"
      },
      "source": [
        "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin new Train!\n",
            "-- Partidas[ 500 ] Avg.Puntos[ 14 ]  AVG Steps[ 219 ] Max Score[ 210 ]\n",
            "-- Partidas[ 1000 ] Avg.Puntos[ 19 ]  AVG Steps[ 237 ] Max Score[ 210 ]\n",
            "-- Partidas[ 1500 ] Avg.Puntos[ 20 ]  AVG Steps[ 241 ] Max Score[ 280 ]\n",
            "-- Partidas[ 2000 ] Avg.Puntos[ 21 ]  AVG Steps[ 244 ] Max Score[ 280 ]\n",
            "-- Partidas[ 2500 ] Avg.Puntos[ 25 ]  AVG Steps[ 257 ] Max Score[ 410 ]\n",
            "-- Partidas[ 3000 ] Avg.Puntos[ 28 ]  AVG Steps[ 267 ] Max Score[ 410 ]\n",
            "-- Partidas[ 3500 ] Avg.Puntos[ 31 ]  AVG Steps[ 278 ] Max Score[ 410 ]\n",
            "-- Partidas[ 4000 ] Avg.Puntos[ 35 ]  AVG Steps[ 289 ] Max Score[ 410 ]\n",
            "-- Partidas[ 4500 ] Avg.Puntos[ 37 ]  AVG Steps[ 297 ] Max Score[ 410 ]\n",
            "Partidas[ 4999 ] Avg.Puntos[ 39 ] Max score[ 410 ] en partida[ 2218 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vjur3_PTDlgU",
        "outputId": "a3b94c23-3847-4a0c-cc7d-62ab4e5c702b"
      },
      "source": [
        "\n",
        "learner2 = PongAgent(game, policy=learner.get_policy())\n",
        "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
        "player = play(rounds=1, learner=learner2, game=game, animate=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJiBYpc7PM6-"
      },
      "source": [
        "import gym #Creacion del entorno para pruebas en FrozenLaken\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31jwKYx6P_74",
        "outputId": "5945e070-4283-4f0a-cd18-658930f9af79"
      },
      "source": [
        "\n",
        "\n",
        "env = gym.make('FrozenLake-v0',is_slippery=False) \n",
        "#Creacion del entorno\n",
        "env.reset()  \n",
        "env.render()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbWtGyfqRP9p",
        "outputId": "b4f46215-45ac-47b5-b195-84d5d3f87cf0"
      },
      "source": [
        "#AGENTE TORPE INDICA EL NUMERO DE ACCIONES POSIBLES\n",
        "is_done = False\n",
        "t = 0\n",
        "while not is_done:\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, is_done, _ = env.step(action)\n",
        "    env.render()\n",
        "    t += 1\n",
        "print('\\ nlast state =', state)\n",
        "print('reward = ', reward)\n",
        "print('time steps =', t)\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "\\ nlast state = 5\n",
            "reward =  0.0\n",
            "time steps = 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsfCH3LXS-7K"
      },
      "source": [
        "state, reward, is_done, _ = env.step(action)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "3osWyx74TJNK",
        "outputId": "ad17a524-8f2c-4027-d349-6b8892a79406"
      },
      "source": [
        "env = gym.make('FrozenLake-v0',is_slippery=False) \n",
        "#Creacion del entorno\n",
        "env.reset()  \n",
        "env.render()\n",
        "is_done=False\n",
        "t=0\n",
        "#Creamos agente\n",
        " \n",
        "agent=Agent()\n",
        "while not is_done:\n",
        "    action = agent.select_action()\n",
        "    state ,reward, is_done, _ = env.step(action)\n",
        "    env.render()\n",
        "    t+=1\n",
        "print('\\ nlast state =', state)\n",
        "print('reward = ', reward)\n",
        "print('time steps =', t)\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-79c90aecaf17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-b2065179f503>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Agent' object has no attribute 'internalenv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRss0OH-UuN5"
      },
      "source": [
        "#agente\n",
        "class Agent:\n",
        "\n",
        "  def _int_(self):\n",
        "    self.internalenv = gym.make('FrozenLake-v0',is_slippery=False) \n",
        "  \n",
        "  def select_action (self):\n",
        "    return self.internalenv.action_space.sample()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io755dlIU3iI"
      },
      "source": [
        "def test(agent,test_env):\n",
        "  env.reset()\n",
        "  is_done=False\n",
        "  t=0\n",
        "  while not is_done:\n",
        "    action =agent.select_action()\n",
        "    state, reward, is_done, _=env.step(action)\n",
        "    t+= 1\n",
        "    return(state,reward,is_done)\n",
        "  agent=Agent()\n",
        "  env=gym.make('FrozenLake-v0',is_slippery=False) \n",
        "  solved=0\n",
        "  for episode in range(1000):\n",
        "    state,reward, is_done =test(agent,env)\n",
        "    if(state ==15):\n",
        "         solved += 1\n",
        "  \n",
        "  print(f'Solved{solved} times({solved/10}%)')"
      ],
      "execution_count": 74,
      "outputs": []
    }
  ]
}